import sentencepiece as spm
import os

if __name__ == '__main__':
    # å®šä¹‰è¯­æ–™æ–‡ä»¶è·¯å¾„
    corpus = "token.txt"

    # å®šä¹‰åˆ†è¯å™¨çš„æ¨¡å‹åç§°
    model_prefix = "spm_dict_v2.1"

    # è®­ç»ƒåˆ†è¯å™¨
    spm.SentencePieceTrainer.train(     # type: ignore
        input=corpus,                   # è¾“å…¥è¯­æ–™æ–‡ä»¶
        model_prefix=model_prefix,      # è¾“å‡ºæ¨¡å‹å‰ç¼€
        vocab_size=78336,               # è¯æ±‡è¡¨å¤§å°
        model_type='bpe',               # åˆ†è¯æ¨¡å‹ç±»å‹
        max_sentencepiece_length=8,     # æœ€é•¿å•åˆ†è¯å­—æ•°
        input_format="text",            # è¾“å…¥çº¯æ–‡æœ¬æ–‡ä»¶
        max_sentence_length=32768,      # è®­ç»ƒæ—¶æœ€å¤§å…è®¸çš„å¥å­é•¿åº¦
        byte_fallback=True,             # å¯ç”¨å­—èŠ‚å›é€€æœºåˆ¶
        character_coverage=0.9997,      # å­—ç¬¦è¦†ç›–ç‡
        split_digits=True,              # å°†æ•°å­—æ‹†åˆ†ä¸ºå•ä¸ªtoken
        num_threads=os.cpu_count(),     # ä½¿ç”¨çš„çº¿ç¨‹æ•°
        self_test_sample_size=0,        # è‡ªæµ‹æ ·æœ¬çš„å¤§å°
        unk_surface=r" \342\201\207 ",  # æŒ‡å®šæœªçŸ¥å­—ç¬¦å½¢å¼
        pad_id=3,                       # è®¾ç½®pad_id    
        user_defined_symbols=['<user>', '<bot>', 'ğŸ˜€','ğŸ˜ƒ','ğŸ˜„','ğŸ˜…','ğŸ˜‚','ğŸ˜—','ğŸ˜™','ğŸ˜š','ğŸ˜Š','ğŸ™ƒ','ğŸ™‚','ğŸ˜‘','ğŸ˜','ğŸ«¢','ğŸ¤­','ğŸ¥±','ğŸ¤—','ğŸ«£','ğŸ˜±','ğŸ¤¨','ğŸ§','ğŸ˜’','ğŸ˜§','ğŸ˜Ÿ','ğŸ™„','ğŸ˜¥','ğŸ˜¦','ğŸ˜®â€ğŸ’¨','ğŸ˜¢','ğŸ˜®','ğŸ˜¤','â˜¹ï¸','ğŸ˜¯','ğŸ˜ ','ğŸ™','ğŸ˜²','ğŸ˜¡','ğŸ«¤','ğŸ˜³','ğŸ¤¬','ğŸ˜•','ğŸ¤¯','ğŸ¥µ','ğŸ¤¢','ğŸ¤®','ğŸ˜–','ğŸ˜£','ğŸ˜°','ğŸ˜¨','ğŸ˜','ğŸ˜“','â¤ï¸','âœŒï¸','ğŸ«²','ğŸ«±','ğŸ’ª','ğŸ‘','ğŸ‘','ğŸ‘','ğŸ¤œ','ğŸ¤›','âœŠ','ğŸ‘Š','ğŸ¥°','ğŸ˜','ğŸ¤ª','ğŸ¤“','tower','GPT','Midway']
        # æ·»åŠ æ ¼å¤–åˆ†è¯
    )

    print(f"æ¨¡å‹å·²è®­ç»ƒå®Œæˆ,å¹¶ä¿å­˜ä¸º {model_prefix}.modelå’Œ{model_prefix}.vocab")

